# ç´”ç²‹ãªRAG

## 1. RAGæ§‹ç¯‰
å‚è€ƒï¼‰https://zenn.dev/minedia/articles/21d5b4b23e38eb#%E3%83%81%E3%83%A3%E3%83%83%E3%83%88ui%E3%81%A8%E3%83%81%E3%83%A3%E3%83%83%E3%83%88%E3%81%AE%E3%83%AD%E3%82%B8%E3%83%83%E3%82%AF%E3%81%AE%E6%A7%8B%E7%AF%89

```
-- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆï¼ˆåç§°å¤‰ãˆã‚Œã°è‰¯ã‹ã£ãŸã€‚ã€‚ã€‚ï¼‰
CREATE DATABASE DIGITAL_AGENCY_CORTEX_DOCS;

-- ã‚¹ã‚­ãƒ¼ãƒä½œæˆ
CREATE SCHEMA DATA;

-- PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’Langchainã§èª­ã¿å–ã‚Šãƒãƒ£ãƒ³ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã™ã‚‹
create or replace function pdf_text_chunker(file_url string)
returns table (chunk varchar)
language python
runtime_version = '3.9'
handler = 'pdf_text_chunker'
packages = ('snowflake-snowpark-python','PyPDF2', 'langchain')
as
$$
from snowflake.snowpark.types import StringType, StructField, StructType
from langchain.text_splitter import RecursiveCharacterTextSplitter
from snowflake.snowpark.files import SnowflakeFile
import PyPDF2, io
import logging
import pandas as pd

class pdf_text_chunker:

    def read_pdf(self, file_url: str) -> str:
    
        logger = logging.getLogger("udf_logger")
        logger.info(f"Opening file {file_url}")
    
        with SnowflakeFile.open(file_url, 'rb') as f:
            buffer = io.BytesIO(f.readall())
            
        reader = PyPDF2.PdfReader(buffer)   
        text = ""
        for page in reader.pages:
            try:
                text += page.extract_text().replace('\n', ' ').replace('\0', ' ')
            except:
                text = "Unable to Extract"
                logger.warn(f"Unable to extract from file {file_url}, page {page}")
        
        return text

    def process(self,file_url: str):

        text = self.read_pdf(file_url)
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size = 4000, #Adjust this as you see fit
            chunk_overlap  = 400, #This let's text have some form of overlap. Useful for keeping chunks contextual
            length_function = len
        )
    
        chunks = text_splitter.split_text(text)
        df = pd.DataFrame(chunks, columns=['chunks'])
        
        yield from df.itertuples(index=False, name=None)
$$;

-- PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’ä½œæˆã™ã‚‹
create or replace stage docs ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = ( ENABLE = true );

-- ãƒãƒ£ãƒ³ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«
create or replace TABLE DOCS_CHUNKS_TABLE ( 
    RELATIVE_PATH VARCHAR(16777216), -- PDFãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ç›¸å¯¾ãƒ‘ã‚¹
    SIZE NUMBER(38,0), -- PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚º
    FILE_URL VARCHAR(16777216), -- PDFã®URL
    SCOPED_FILE_URL VARCHAR(16777216), -- ã‚¹ã‚³ãƒ¼ãƒ—ä»˜ãURL
    CHUNK VARCHAR(16777216), -- ãƒ†ã‚­ã‚¹ãƒˆã®ä¸€éƒ¨
    CHUNK_VEC VECTOR(FLOAT, 768) );  -- VECTORãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®åŸ‹ã‚è¾¼ã¿

-- ãƒãƒ£ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«ã¸ã®ç™»éŒ²ã€SELECTå¥å†…ã§embed
insert into docs_chunks_table (relative_path, size, file_url,
                            scoped_file_url, chunk, chunk_vec)
    select relative_path, 
            size,
            file_url, 
            build_scoped_file_url(@docs, relative_path) as scoped_file_url,
            func.chunk as chunk,
            SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2',chunk) as chunk_vec
    from 
        directory(@docs),
        TABLE(pdf_text_chunker(build_scoped_file_url(@docs, relative_path))) as func;

        
-- ç¢ºèªç”¨
select relative_path, size, chunk, chunk_vec from docs_chunks_table limit 5;

select relative_path, count(*) as num_chunks 
    from docs_chunks_table
    group by relative_path;

```

## 2. ã‚¢ãƒ—ãƒªæ§‹ç¯‰
streamlitã§ä¸‹è¨˜ã‚’å®Ÿè£…
```
import streamlit as st # Import python packages
from snowflake.snowpark.context import get_active_session
session = get_active_session() # Get the current credentials

import pandas as pd

pd.set_option("max_colwidth",None)
num_chunks = 3 # Num-chunks provided as context. Play with this to check how it affects your accuracy

def create_prompt (myquestion, rag):

    if rag == 1:    

        cmd = """
         with results as
         (SELECT RELATIVE_PATH,
           VECTOR_COSINE_SIMILARITY(docs_chunks_table.chunk_vec,
                    SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', ?)) as similarity,
           chunk
         from docs_chunks_table
         order by similarity desc
         limit ?)
         select chunk, relative_path from results 
         """
    
        df_context = session.sql(cmd, params=[myquestion, num_chunks]).to_pandas()      
        
        context_lenght = len(df_context) -1

        prompt_context = ""
        for i in range (0, context_lenght):
            prompt_context += df_context._get_value(i, 'CHUNK')

        prompt_context = prompt_context.replace("'", "")
        relative_path =  df_context._get_value(0,'RELATIVE_PATH')
    
        prompt = f"""
          'ã‚ãªãŸã¯ã€æ—¥æœ¬èªã‚’è©±ã™æä¾›ã•ã‚ŒãŸæ–‡è„ˆã‹ã‚‰æƒ…å ±ã‚’å¼•ãå‡ºã™å°‚é–€å®¶ã§ã™ã€‚æ–‡è„ˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
          ç°¡æ½”ã«ã€ãã—ã¦æƒ³åƒã‚’è†¨ã‚‰ã¾ã›ãªã„ã§ãã ã•ã„ã€‚æƒ…å ±ãŒãªã„å ´åˆã«ã¯ã€ãã®æ—¨ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
          ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {prompt_context}
          è³ªå•:  
           {myquestion} 
           å›ç­”: '
           """
        cmd2 = f"select GET_PRESIGNED_URL(@docs, '{relative_path}', 360) as URL_LINK from directory(@docs)"
        df_url_link = session.sql(cmd2).to_pandas()
        url_link = df_url_link._get_value(0,'URL_LINK')

    else:
        prompt = f"""ã‚ãªãŸã¯ã€æ—¥æœ¬èªã‚’è©±ã™ã€‚
         'Question:  
           {myquestion} 
           Answer: '
           """
        url_link = "None"
        relative_path = "None"
        
    return prompt, url_link, relative_path

def complete(myquestion, model_name, rag = 1):

    prompt, url_link, relative_path =create_prompt (myquestion, rag)
    cmd = f"""
             select SNOWFLAKE.CORTEX.COMPLETE(?,?) as response
           """
    
    df_response = session.sql(cmd, params=[model_name, prompt]).collect()
    return df_response, url_link, relative_path

def display_response (question, model, rag=0):
    response, url_link, relative_path = complete(question, model, rag)
    res_text = response[0].RESPONSE
    st.markdown(res_text)
    if rag == 1:
        display_url = f"Link to [{relative_path}]({url_link}) that may be useful"
        st.markdown(display_url)

#Main code

st.title("Snowflake Cortex ã‚’ä½¿ç”¨ã—ã¦è‡ªåˆ†ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è³ªå•ã™ã‚‹:")
st.write("ã‚ãªãŸã¯è³ªå•ã‚’ã—ã€æ–‡è„ˆã®ãŸã‚ã«ã‚ãªãŸã®æ–‡æ›¸ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€ãƒ¢ãƒ‡ãƒ«ã«ç‹¬è‡ªã®å¿œç­”ã‚’ä½œæˆã•ã›ã‚‹ã‹ã‚’æ±ºå®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")
st.write("ã“ã‚Œã¯ã€ã‚ãªãŸãŒã™ã§ã«æŒã£ã¦ã„ã‚‹æ›¸é¡ã®ãƒªã‚¹ãƒˆã§ã™ã€‚:")
docs_available = session.sql("ls @docs").collect()
list_docs = []
for doc in docs_available:
    list_docs.append(doc["name"])
st.dataframe(list_docs)

#Here you can choose what LLM to use. Please note that they will have different cost & performance
model = st.sidebar.selectbox('Select your model:',(
                                     'mistral-7b'))

question = st.text_input("Enter question", placeholder="ç”ŸæˆAIã‚’åˆ©ç”¨ã™ã‚‹ä¸Šã§ã®ãƒªã‚¹ã‚¯ã¯ï¼Ÿ", label_visibility="collapsed")

rag = st.sidebar.checkbox('è‡ªåˆ†ã®æ–‡æ›¸ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ã†?')

print (rag)

if rag:
    use_rag = 1
else:
    use_rag = 0

if question:
    display_response (question, model, use_rag)
```

## 3. RAGã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã®ã‹è©¦é‹è»¢

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚¢ã‚¯ã‚¢ã®æœ€æ–°PDFã‚’ã“ã¡ã‚‰ã‹ã‚‰å–å¾—ã—ã¦ç™»éŒ²
https://toyota.jp/request/webcatalog/

RAGã‚ã‚Šã®å ´åˆã€ãƒ–ãƒ¬ãƒ¼ã‚­æ©Ÿèƒ½ã«ã¤ã„ã¦PDFã«æ›¸ã„ã¦ã‚ã‚‹è©³ç´°ãªå†…å®¹ã‚’ç­”ãˆã¦ãã‚Œã¦ã„ãã†ã€‚
![RAGã‚ã‚Š](images/rag1.png)

RAGãªã—ã®å ´åˆã€é›‘ãªå†…å®¹ã€‚RAGã¨ã—ã¦æ©Ÿèƒ½ã—ã¦ã„ãã†ã€‚
![RAGãªã—](images/rag2.png)

## 4. Cortexåˆ†æã¨çµ±åˆã—ã¦ã¿ã‚‹
- ãƒãƒ£ãƒƒãƒˆã—ã¦
- RAGã—ã¦
- Cortexåˆ†æã«æŒ‡ç¤ºã¨RAGã‚’ä¸€ç·’ã«æ¸¡ã—ã¦åˆ†æã—ã¦ã‚‚ã‚‰ã†
çš„ãªã“ã¨ãŒã—ãŸã„ã€‚
```
import _snowflake
import json
import streamlit as st
import time
from snowflake.snowpark.context import get_active_session

# Cortex Analyticsè¨­å®š
DATABASE = "TESTDB"
SCHEMA   = "PUBLIC"
STAGE    = "MY_INT_STAGE"
FILE     = "MYMODEL.yaml"  # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã®YAMLãƒ•ã‚¡ã‚¤ãƒ«å

# RAGè¨­å®š
num_chunks = 3  # å–å¾—ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯æ•°

def get_rag_context(question):
    """RAGã‹ã‚‰é–¢é€£æ–‡ç« ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
    try:
        # RAGã‹ã‚‰é–¢é€£æ–‡ç« ã‚’å–å¾—
        cmd = """
         with results as
         (SELECT RELATIVE_PATH,
           VECTOR_COSINE_SIMILARITY(docs_chunks_table.chunk_vec,
                    SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', ?)) as similarity,
           chunk
         from DIGITAL_AGENCY_CORTEX_DOCS.DATA.DOCS_CHUNKS_TABLE
         order by similarity desc
         limit ?)
         select chunk, relative_path, similarity from results 
         """
        
        session = get_active_session()
        df_context = session.sql(cmd, params=[question, num_chunks]).to_pandas()
        
        if len(df_context) == 0:
            return None, None, None
            
        # é–¢é€£æ–‡ç« ã‚’çµåˆ
        context_text = ""
        for i in range(len(df_context)):
            context_text += df_context._get_value(i, 'CHUNK') + "\n\n"

        relative_path = df_context._get_value(0, 'RELATIVE_PATH')
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®URLã‚’å–å¾—
        cmd2 = f"select GET_PRESIGNED_URL(@docs, '{relative_path}', 360) as URL_LINK from directory(@docs)"
        df_url_link = session.sql(cmd2).to_pandas()
        url_link = df_url_link._get_value(0, 'URL_LINK')
        
        return context_text, url_link, relative_path
        
    except Exception as e:
        st.error(f"RAGã‹ã‚‰é–¢é€£æ–‡ç« ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None, None, None

def send_message(prompt: str, rag_context: str = None) -> dict:
    """Calls the REST API and returns the response."""
    # RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    if rag_context:
        enhanced_prompt = f"""
        ä»¥ä¸‹ã®RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‚è€ƒã«ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
        
        RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
        {rag_context}
        
        è³ªå•: {prompt}
        
        ä¸Šè¨˜ã®RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸºã«ã€è©³ç´°ã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        """
    else:
        enhanced_prompt = prompt
    
    request_body = {
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": enhanced_prompt
                    }
                ]
            }
        ],
        "semantic_model_file": f"@{DATABASE}.{SCHEMA}.{STAGE}/{FILE}",
    }
    resp = _snowflake.send_snow_api_request(
        "POST",
        f"/api/v2/cortex/analyst/message",
        {},
        {},
        request_body,
        {},
        30000,
    )
    if resp["status"] < 400:
        return json.loads(resp["content"])
    else:
        raise Exception(
            f"Failed request with status {resp['status']}: {resp}"
        )

def process_message(prompt: str, use_rag: bool = True) -> None:
    """Processes a message and adds the response to the chat."""
    st.session_state.messages.append(
        {"role": "user", "content": [{"type": "text", "text": prompt}]}
    )
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        # RAGã‹ã‚‰é–¢é€£æ–‡ç« ã‚’å–å¾—
        rag_context = None
        if use_rag:
            with st.spinner("RAGã‹ã‚‰é–¢é€£æ–‡ç« ã‚’å–å¾—ä¸­..."):
                rag_context, url_link, relative_path = get_rag_context(prompt)
                if rag_context:
                    st.success("âœ… RAGé–¢é€£æ–‡ç« ã‚’å–å¾—ã—ã¾ã—ãŸ")
                    # RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
                    with st.expander("ğŸ“„ å–å¾—ã•ã‚ŒãŸRAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", expanded=False):
                        st.text(rag_context)
                else:
                    st.warning("âš ï¸ RAGé–¢é€£æ–‡ç« ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        # Cortex Analyticsã§åˆ†æ
        with st.spinner("Cortex Analyticsã§åˆ†æä¸­..."):
            response = send_message(prompt=prompt, rag_context=rag_context)
            content = response["message"]["content"]
            display_content(content=content)
    st.session_state.messages.append({"role": "assistant", "content": content})

def display_content(content: list, message_index: int = None) -> None:
    """Displays a content item for a message."""
    message_index = message_index or len(st.session_state.messages)
    for item in content:
        if item["type"] == "text":
            st.markdown(item["text"])
        elif item["type"] == "suggestions":
            with st.expander("Suggestions", expanded=True):
                for suggestion_index, suggestion in enumerate(item["suggestions"]):
                    if st.button(suggestion, key=f"{message_index}_{suggestion_index}"):
                        st.session_state.active_suggestion = suggestion
        elif item["type"] == "sql":
            with st.expander("SQL Query", expanded=False):
                st.code(item["statement"], language="sql")
            with st.expander("Results", expanded=True):
                with st.spinner("Running SQL..."):
                    session = get_active_session()
                    df = session.sql(item["statement"]).to_pandas()
                    # SQLçµæœã‚’Dataã®ã¿ã§è¡¨ç¤º
                    st.dataframe(df)
            

st.title("RAGçµ±åˆ Cortex Analytics")
st.markdown(f"**ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«:** `{FILE}`")
st.write("**åˆ†æãƒ•ãƒ­ãƒ¼:** ãƒãƒ£ãƒƒãƒˆå…¥åŠ› â†’ RAGå–å¾— â†’ RAGã‚’Analyticsã«æ¸¡ã™ â†’ Analyticsã®å›ç­”ã‚’è¡¨ç¤º")


# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("âš™ï¸ è¨­å®š")
use_rag = st.sidebar.checkbox('RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹', value=True)

if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.suggestions = []
    st.session_state.active_suggestion = None

for message_index, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        display_content(content=message["content"], message_index=message_index)

if user_input := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆRAG + Cortex Analyticsï¼‰..."):
    process_message(prompt=user_input, use_rag=use_rag)

if st.session_state.active_suggestion:
    process_message(prompt=st.session_state.active_suggestion, use_rag=use_rag)
    st.session_state.active_suggestion = None
```
ã“ã‚“ãªæ„Ÿã˜
![RAGã¨ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚’çµ±åˆ](images/rag3.png)